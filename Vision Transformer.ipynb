{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84705,"databundleVersionId":9755748,"sourceType":"competition"},{"sourceId":9833736,"sourceType":"datasetVersion","datasetId":6031662},{"sourceId":9834134,"sourceType":"datasetVersion","datasetId":6031980}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-13T09:26:18.542396Z","iopub.execute_input":"2024-11-13T09:26:18.543098Z","iopub.status.idle":"2024-11-13T09:26:18.547652Z","shell.execute_reply.started":"2024-11-13T09:26:18.543054Z","shell.execute_reply":"2024-11-13T09:26:18.546753Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/visual-taxonomy/train.csv\")\ndf2 = pd.read_csv(\"/kaggle/input/visual-taxonomy/test.csv\")\nsample = pd.read_csv('/kaggle/input/visual-taxonomy/sample_submission.csv')\ndf1[\"id\"] = df1[\"id\"].astype(str).str.zfill(6)\ndf2[\"id\"] = df2[\"id\"].astype(str).str.zfill(6)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:18.548798Z","iopub.execute_input":"2024-11-13T09:26:18.549121Z","iopub.status.idle":"2024-11-13T09:26:18.896822Z","shell.execute_reply.started":"2024-11-13T09:26:18.549089Z","shell.execute_reply":"2024-11-13T09:26:18.895999Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df1['image_path'] = df1['id'].apply(lambda x: f\"/kaggle/input/visual-taxonomy/train_images/{str(x).zfill(6)}.jpg\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:18.898309Z","iopub.execute_input":"2024-11-13T09:26:18.899005Z","iopub.status.idle":"2024-11-13T09:26:18.946737Z","shell.execute_reply.started":"2024-11-13T09:26:18.898968Z","shell.execute_reply":"2024-11-13T09:26:18.945793Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Calculate the number of rows to remove based on the condition\nrem_row = df1.index[df1.apply(lambda row: row.isna().sum() > 13 - row['len'], axis=1)].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:18.948280Z","iopub.execute_input":"2024-11-13T09:26:18.948627Z","iopub.status.idle":"2024-11-13T09:26:24.822224Z","shell.execute_reply.started":"2024-11-13T09:26:18.948584Z","shell.execute_reply":"2024-11-13T09:26:24.821218Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# rem_row = []\n# for i in range(df1.shape[0]):\n#     if df1.iloc[i,:].isna().sum() > 11 - df1.loc[i,'len']:\n#         rem_row.append(i)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.823538Z","iopub.execute_input":"2024-11-13T09:26:24.823944Z","iopub.status.idle":"2024-11-13T09:26:24.828501Z","shell.execute_reply.started":"2024-11-13T09:26:24.823897Z","shell.execute_reply":"2024-11-13T09:26:24.827384Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df1.drop(rem_row, axis = 0, inplace = True)\ndf1.reset_index(drop= True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.829685Z","iopub.execute_input":"2024-11-13T09:26:24.830003Z","iopub.status.idle":"2024-11-13T09:26:24.867688Z","shell.execute_reply.started":"2024-11-13T09:26:24.829958Z","shell.execute_reply":"2024-11-13T09:26:24.867004Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# for i in range(df1.shape[0]):\n#     if df1.iloc[i,:].isna().sum() == 10 - df1.loc[i,'len']:\n#         df1.iloc[i,:] = df1.iloc[i,:].fillna(\"extra\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.871784Z","iopub.execute_input":"2024-11-13T09:26:24.872441Z","iopub.status.idle":"2024-11-13T09:26:24.876037Z","shell.execute_reply.started":"2024-11-13T09:26:24.872407Z","shell.execute_reply":"2024-11-13T09:26:24.875100Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.880068Z","iopub.execute_input":"2024-11-13T09:26:24.880412Z","iopub.status.idle":"2024-11-13T09:26:24.905212Z","shell.execute_reply.started":"2024-11-13T09:26:24.880378Z","shell.execute_reply":"2024-11-13T09:26:24.904408Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           id             Category  len      attr_1   attr_2   attr_3  \\\n0      000000          Men Tshirts    5     default    round  printed   \n1      000001          Men Tshirts    5  multicolor     polo    solid   \n2      000002          Men Tshirts    5     default     polo    solid   \n3      000003          Men Tshirts    5  multicolor     polo    solid   \n4      000004          Men Tshirts    5  multicolor     polo    solid   \n...       ...                  ...  ...         ...      ...      ...   \n53288  070373  Women Tops & Tunics   10        blue  regular  regular   \n53289  070374  Women Tops & Tunics   10  multicolor   fitted  regular   \n53290  070375  Women Tops & Tunics   10      yellow  regular     crop   \n53291  070376  Women Tops & Tunics   10      maroon   fitted     crop   \n53292  070378  Women Tops & Tunics   10        pink     boxy     crop   \n\n            attr_4         attr_5   attr_6      attr_7         attr_8  \\\n0          default  short sleeves      NaN         NaN            NaN   \n1            solid  short sleeves      NaN         NaN            NaN   \n2            solid  short sleeves      NaN         NaN            NaN   \n3            solid  short sleeves      NaN         NaN            NaN   \n4            solid  short sleeves      NaN         NaN            NaN   \n...            ...            ...      ...         ...            ...   \n53288   round neck         casual    solid       solid  short sleeves   \n53289  square neck         casual  printed     default  short sleeves   \n53290   round neck         casual  default     default  short sleeves   \n53291   round neck         casual    solid       solid  short sleeves   \n53292       v-neck         casual  printed  typography  short sleeves   \n\n                attr_9  attr_10  \\\n0                  NaN      NaN   \n1                  NaN      NaN   \n2                  NaN      NaN   \n3                  NaN      NaN   \n4                  NaN      NaN   \n...                ...      ...   \n53288          default  knitted   \n53289  regular sleeves  ruffles   \n53290  regular sleeves  knitted   \n53291  regular sleeves  knitted   \n53292  regular sleeves      NaN   \n\n                                              image_path  \n0      /kaggle/input/visual-taxonomy/train_images/000...  \n1      /kaggle/input/visual-taxonomy/train_images/000...  \n2      /kaggle/input/visual-taxonomy/train_images/000...  \n3      /kaggle/input/visual-taxonomy/train_images/000...  \n4      /kaggle/input/visual-taxonomy/train_images/000...  \n...                                                  ...  \n53288  /kaggle/input/visual-taxonomy/train_images/070...  \n53289  /kaggle/input/visual-taxonomy/train_images/070...  \n53290  /kaggle/input/visual-taxonomy/train_images/070...  \n53291  /kaggle/input/visual-taxonomy/train_images/070...  \n53292  /kaggle/input/visual-taxonomy/train_images/070...  \n\n[53293 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53288</th>\n      <td>070373</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>blue</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>default</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53289</th>\n      <td>070374</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>multicolor</td>\n      <td>fitted</td>\n      <td>regular</td>\n      <td>square neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53290</th>\n      <td>070375</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>yellow</td>\n      <td>regular</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>default</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53291</th>\n      <td>070376</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>maroon</td>\n      <td>fitted</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53292</th>\n      <td>070378</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>pink</td>\n      <td>boxy</td>\n      <td>crop</td>\n      <td>v-neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>typography</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n  </tbody>\n</table>\n<p>53293 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# #new one\n\n# import pandas as pd\n# from sklearn.compose import ColumnTransformer\n# from sklearn.impute import SimpleImputer\n\n# # Function to apply SimpleImputer on the useful columns for a specific category\n# def apply_column_transformer(df_temp):\n#     # Get the maximum number of useful attributes for this category based on the 'len' column\n#     max_len = df_temp['len'].max()\n    \n#     # Create a list of useful columns (e.g., 'attr_1', 'attr_2', ..., 'attr_max_len')\n#     useful_columns = [f'attr_{i}' for i in range(1, max_len + 1)]\n    \n#     # Create a ColumnTransformer to apply SimpleImputer to only the useful columns\n#     column_transformer = ColumnTransformer(\n#         transformers=[\n#             ('imputer', SimpleImputer(strategy='most_frequent'), useful_columns)  # Impute only the useful columns\n#         ],\n#         remainder='passthrough'  # Leave other columns unchanged\n#     )\n    \n#     # Apply the transformer (fit and transform)\n#     transformed_array = column_transformer.fit_transform(df_temp)\n    \n#     # Now manually combine the transformed useful columns and the non-transformed columns\n#     df_temp_imputed = pd.DataFrame(transformed_array, columns=useful_columns + [col for col in df_temp.columns if col not in useful_columns])\n    \n#     # Reset index of the imputed DataFrame to match original DataFrame\n#     df_temp_imputed.index = df_temp.index  # Ensure the indices are the same\n    \n#     # Ensure data types are preserved for columns that exist in both DataFrames\n#     for col in df_temp.columns:\n#         if col in df_temp_imputed.columns:  # Check if the column exists in the transformed DataFrame\n#             df_temp_imputed[col] = df_temp_imputed[col].astype(df_temp[col].dtype)\n    \n#     return df_temp_imputed","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.906267Z","iopub.execute_input":"2024-11-13T09:26:24.906549Z","iopub.status.idle":"2024-11-13T09:26:24.911686Z","shell.execute_reply.started":"2024-11-13T09:26:24.906518Z","shell.execute_reply":"2024-11-13T09:26:24.910821Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# df_imputed = df1.copy()\n\n# # Get all unique categories in the dataset\n# categories = df_imputed['Category'].unique()\n\n# # Loop over each category and apply the column transformer function\n# for category in categories:\n#     # Step 1: Filter the DataFrame for the current category\n#     df_temp = df_imputed[df_imputed['Category'] == category].copy()\n    \n#     # Step 2: Apply the column transformer to this category's DataFrame\n#     df_temp_imputed = apply_column_transformer(df_temp)\n    \n#     # Step 3: Update the original DataFrame with the imputed values\n#     # Determine the useful columns for this category\n#     useful_columns = [f'attr_{i}' for i in range(1, df_temp['len'].max() + 1)]\n    \n#     # Assign the imputed values back to the original DataFrame\n#     df_imputed.loc[df_temp.index, useful_columns] = df_temp_imputed[useful_columns]","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.912954Z","iopub.execute_input":"2024-11-13T09:26:24.913230Z","iopub.status.idle":"2024-11-13T09:26:24.922912Z","shell.execute_reply.started":"2024-11-13T09:26:24.913199Z","shell.execute_reply":"2024-11-13T09:26:24.922184Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import KNNImputer\nfrom sklearn.preprocessing import OrdinalEncoder\n\ndef apply_knn_imputer_categorical(df_temp, n_neighbors=25):\n    \n    max_len = df_temp['len'].max()\n    useful_columns = [f'attr_{i}' for i in range(1, max_len + 1)]\n    \n    encoder = OrdinalEncoder()\n    df_encoded = df_temp.copy()\n#     print(df_temp[useful_columns])\n    df_encoded[useful_columns] = encoder.fit_transform(df_temp[useful_columns])\n    imputer = KNNImputer(n_neighbors=n_neighbors)\n    df_imputed_array = imputer.fit_transform(df_encoded[useful_columns])\n    \n    df_imputed = pd.DataFrame(df_imputed_array, columns=useful_columns, index=df_temp.index)\n#     print(df_imputed)\n    \n    df_imputed[useful_columns] = df_imputed[useful_columns].round().astype(int)\n#     print(df_imputed)\n    \n    df_imputed[useful_columns] = encoder.inverse_transform(df_imputed[useful_columns])\n#     print(df_imputed)\n    cols = [x for x in df_temp.columns.tolist() if x not in useful_columns]\n    df_imputed = pd.concat([df_imputed, df_temp[cols]], axis = 1)\n    df_imputed = df_imputed[df_temp.columns]\n#     print(df_imputed)\n    \n    return df_imputed\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:24.924042Z","iopub.execute_input":"2024-11-13T09:26:24.925095Z","iopub.status.idle":"2024-11-13T09:26:25.840810Z","shell.execute_reply.started":"2024-11-13T09:26:24.925061Z","shell.execute_reply":"2024-11-13T09:26:25.839806Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Create a copy of the original DataFrame to work on\ndf_imputed = df1.copy()\n\n# Get all unique categories in the dataset\ncategories = df_imputed['Category'].unique()\n\n# Loop over each category and apply the column transformer function\nfor category in categories:\n    # Step 1: Filter the DataFrame for the current category\n    df_temp = df_imputed[df_imputed['Category'] == category].copy()\n    \n    # Step 2: Apply the column transformer to this category's DataFrame\n    df_temp_imputed = apply_knn_imputer_categorical(df_temp)\n    \n    # Step 3: Update the original DataFrame with the imputed values\n    # Determine the useful columns for this category\n    useful_columns = [f'attr_{i}' for i in range(1, df_temp['len'].max() + 1)]\n    \n    # Assign the imputed values back to the original DataFrame\n    df_imputed.loc[df_temp.index, useful_columns] = df_temp_imputed[useful_columns]\n\n# Now, df_imputed contains the imputed values for all categories","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:25.842046Z","iopub.execute_input":"2024-11-13T09:26:25.842576Z","iopub.status.idle":"2024-11-13T09:26:55.175388Z","shell.execute_reply.started":"2024-11-13T09:26:25.842530Z","shell.execute_reply":"2024-11-13T09:26:55.174572Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_imputed","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:55.176834Z","iopub.execute_input":"2024-11-13T09:26:55.177546Z","iopub.status.idle":"2024-11-13T09:26:55.195907Z","shell.execute_reply.started":"2024-11-13T09:26:55.177495Z","shell.execute_reply":"2024-11-13T09:26:55.194810Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"           id             Category  len      attr_1   attr_2   attr_3  \\\n0      000000          Men Tshirts    5     default    round  printed   \n1      000001          Men Tshirts    5  multicolor     polo    solid   \n2      000002          Men Tshirts    5     default     polo    solid   \n3      000003          Men Tshirts    5  multicolor     polo    solid   \n4      000004          Men Tshirts    5  multicolor     polo    solid   \n...       ...                  ...  ...         ...      ...      ...   \n53288  070373  Women Tops & Tunics   10        blue  regular  regular   \n53289  070374  Women Tops & Tunics   10  multicolor   fitted  regular   \n53290  070375  Women Tops & Tunics   10      yellow  regular     crop   \n53291  070376  Women Tops & Tunics   10      maroon   fitted     crop   \n53292  070378  Women Tops & Tunics   10        pink     boxy     crop   \n\n            attr_4         attr_5   attr_6      attr_7         attr_8  \\\n0          default  short sleeves      NaN         NaN            NaN   \n1            solid  short sleeves      NaN         NaN            NaN   \n2            solid  short sleeves      NaN         NaN            NaN   \n3            solid  short sleeves      NaN         NaN            NaN   \n4            solid  short sleeves      NaN         NaN            NaN   \n...            ...            ...      ...         ...            ...   \n53288   round neck         casual    solid       solid  short sleeves   \n53289  square neck         casual  printed     default  short sleeves   \n53290   round neck         casual  default     default  short sleeves   \n53291   round neck         casual    solid       solid  short sleeves   \n53292       v-neck         casual  printed  typography  short sleeves   \n\n                attr_9  attr_10  \\\n0                  NaN      NaN   \n1                  NaN      NaN   \n2                  NaN      NaN   \n3                  NaN      NaN   \n4                  NaN      NaN   \n...                ...      ...   \n53288          default  knitted   \n53289  regular sleeves  ruffles   \n53290  regular sleeves  knitted   \n53291  regular sleeves  knitted   \n53292  regular sleeves  knitted   \n\n                                              image_path  \n0      /kaggle/input/visual-taxonomy/train_images/000...  \n1      /kaggle/input/visual-taxonomy/train_images/000...  \n2      /kaggle/input/visual-taxonomy/train_images/000...  \n3      /kaggle/input/visual-taxonomy/train_images/000...  \n4      /kaggle/input/visual-taxonomy/train_images/000...  \n...                                                  ...  \n53288  /kaggle/input/visual-taxonomy/train_images/070...  \n53289  /kaggle/input/visual-taxonomy/train_images/070...  \n53290  /kaggle/input/visual-taxonomy/train_images/070...  \n53291  /kaggle/input/visual-taxonomy/train_images/070...  \n53292  /kaggle/input/visual-taxonomy/train_images/070...  \n\n[53293 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53288</th>\n      <td>070373</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>blue</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>default</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53289</th>\n      <td>070374</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>multicolor</td>\n      <td>fitted</td>\n      <td>regular</td>\n      <td>square neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53290</th>\n      <td>070375</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>yellow</td>\n      <td>regular</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>default</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53291</th>\n      <td>070376</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>maroon</td>\n      <td>fitted</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n    <tr>\n      <th>53292</th>\n      <td>070378</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>pink</td>\n      <td>boxy</td>\n      <td>crop</td>\n      <td>v-neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>typography</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>knitted</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/070...</td>\n    </tr>\n  </tbody>\n</table>\n<p>53293 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\n\n# Dictionary to hold encoders and data for each category\nencoders = {}\ncategory_dfs_encoded = {}\n\n# Function to one-hot encode the attributes and store the encoder\ndef one_hot_encode_category(df, category, num_attributes):\n    # Initialize OneHotEncoder\n    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n    \n    # Select the useful columns (attributes)\n    useful_columns = [f'attr_{i}' for i in range(1, num_attributes + 1)]\n    \n    # Fit and transform the attributes\n    ohe_encoded = ohe.fit_transform(df[useful_columns])\n    \n    # Store the encoder for later decoding\n    encoders[category] = ohe\n    \n    # Combine the encoded attributes with id, Category, and image_path\n    one_hot_df = pd.concat([df[['id', 'Category', 'image_path']].reset_index(drop=True),\n                            pd.DataFrame(ohe_encoded, columns=ohe.get_feature_names_out())], axis=1)\n    \n    return one_hot_df\n\n# Split the data by category and apply one-hot encoding\ncategory_attributes = {\n    'Men Tshirts': 5,\n    'Sarees': 10,\n    'Kurtis': 9,\n    'Women Tshirts': 8,\n    'Women Tops & Tunics': 10\n}\n\nfor category, num_attributes in category_attributes.items():\n    # Filter the DataFrame by category\n    df_temp = df_imputed[df_imputed['Category'] == category].copy()\n    \n    # Apply one-hot encoding\n    df_encoded = one_hot_encode_category(df_temp, category, num_attributes)\n    \n    # Store the one-hot encoded DataFrame in a dictionary\n    category_dfs_encoded[category] = df_encoded\n\n# Example: Access the one-hot encoded DataFrames for each category\ndf_men_tshirts_encoded = category_dfs_encoded['Men Tshirts']\ndf_sarees_encoded = category_dfs_encoded['Sarees']\ndf_kurtis_encoded = category_dfs_encoded['Kurtis']\ndf_women_tshirts_encoded = category_dfs_encoded['Women Tshirts']\ndf_women_tunics_encoded = category_dfs_encoded['Women Tops & Tunics']\n\n# Print the shape of the one-hot encoded DataFrame for one category\nprint(f\"Shape of Men Tshirts encoded data: {df_men_tshirts_encoded.shape}\")\nprint(f\"Shape of Sarees encoded data: {df_sarees_encoded.shape}\")\nprint(f\"Shape of Kurtis encoded data: {df_kurtis_encoded.shape}\")\nprint(f\"Shape of Women Tshirts encoded data: {df_women_tshirts_encoded.shape}\")\nprint(f\"Shape of Women Tunics encoded data: {df_women_tunics_encoded.shape}\")\n\n# Display the first few rows of the encoded data for \"Men Tshirts\"\nprint(df_kurtis_encoded.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:55.197448Z","iopub.execute_input":"2024-11-13T09:26:55.197809Z","iopub.status.idle":"2024-11-13T09:26:55.456993Z","shell.execute_reply.started":"2024-11-13T09:26:55.197767Z","shell.execute_reply":"2024-11-13T09:26:55.456013Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Shape of Men Tshirts encoded data: (6724, 16)\nShape of Sarees encoded data: (16098, 51)\nShape of Kurtis encoded data: (4330, 33)\nShape of Women Tshirts encoded data: (15565, 32)\nShape of Women Tunics encoded data: (10576, 53)\n       id Category                                         image_path  \\\n0  025778   Kurtis  /kaggle/input/visual-taxonomy/train_images/025...   \n1  025779   Kurtis  /kaggle/input/visual-taxonomy/train_images/025...   \n2  025780   Kurtis  /kaggle/input/visual-taxonomy/train_images/025...   \n3  025781   Kurtis  /kaggle/input/visual-taxonomy/train_images/025...   \n4  025782   Kurtis  /kaggle/input/visual-taxonomy/train_images/025...   \n\n   attr_1_black  attr_1_blue  attr_1_green  attr_1_grey  attr_1_maroon  \\\n0           1.0          0.0           0.0          0.0            0.0   \n1           0.0          0.0           0.0          0.0            0.0   \n2           0.0          0.0           0.0          0.0            0.0   \n3           0.0          0.0           0.0          0.0            0.0   \n4           1.0          0.0           0.0          0.0            0.0   \n\n   attr_1_multicolor  attr_1_navy blue  ...  attr_5_net  attr_6_default  \\\n0                0.0               0.0  ...         1.0             0.0   \n1                0.0               0.0  ...         0.0             1.0   \n2                0.0               0.0  ...         0.0             1.0   \n3                0.0               1.0  ...         0.0             1.0   \n4                0.0               0.0  ...         0.0             1.0   \n\n   attr_6_solid  attr_7_default  attr_7_solid  attr_8_short sleeves  \\\n0           1.0             0.0           1.0                   0.0   \n1           0.0             1.0           0.0                   0.0   \n2           0.0             1.0           0.0                   0.0   \n3           0.0             1.0           0.0                   0.0   \n4           0.0             1.0           0.0                   0.0   \n\n   attr_8_sleeveless  attr_8_three-quarter sleeves  attr_9_regular  \\\n0                0.0                           1.0             1.0   \n1                0.0                           1.0             1.0   \n2                0.0                           1.0             1.0   \n3                0.0                           1.0             1.0   \n4                0.0                           1.0             1.0   \n\n   attr_9_sleeveless  \n0                0.0  \n1                0.0  \n2                0.0  \n3                0.0  \n4                0.0  \n\n[5 rows x 33 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"category_dfs_encoded['Men Tshirts']","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:55.458245Z","iopub.execute_input":"2024-11-13T09:26:55.458569Z","iopub.status.idle":"2024-11-13T09:26:55.490862Z","shell.execute_reply.started":"2024-11-13T09:26:55.458536Z","shell.execute_reply":"2024-11-13T09:26:55.489965Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"          id     Category                                         image_path  \\\n0     000000  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/000...   \n1     000001  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/000...   \n2     000002  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/000...   \n3     000003  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/000...   \n4     000004  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/000...   \n...      ...          ...                                                ...   \n6719  007401  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/007...   \n6720  007412  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/007...   \n6721  007417  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/007...   \n6722  007419  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/007...   \n6723  007426  Men Tshirts  /kaggle/input/visual-taxonomy/train_images/007...   \n\n      attr_1_black  attr_1_default  attr_1_multicolor  attr_1_white  \\\n0              0.0             1.0                0.0           0.0   \n1              0.0             0.0                1.0           0.0   \n2              0.0             1.0                0.0           0.0   \n3              0.0             0.0                1.0           0.0   \n4              0.0             0.0                1.0           0.0   \n...            ...             ...                ...           ...   \n6719           0.0             0.0                1.0           0.0   \n6720           0.0             0.0                1.0           0.0   \n6721           0.0             0.0                1.0           0.0   \n6722           1.0             0.0                0.0           0.0   \n6723           1.0             0.0                0.0           0.0   \n\n      attr_2_polo  attr_2_round  attr_3_printed  attr_3_solid  attr_4_default  \\\n0             0.0           1.0             1.0           0.0             1.0   \n1             1.0           0.0             0.0           1.0             0.0   \n2             1.0           0.0             0.0           1.0             0.0   \n3             1.0           0.0             0.0           1.0             0.0   \n4             1.0           0.0             0.0           1.0             0.0   \n...           ...           ...             ...           ...             ...   \n6719          0.0           1.0             1.0           0.0             1.0   \n6720          0.0           1.0             1.0           0.0             1.0   \n6721          0.0           1.0             1.0           0.0             1.0   \n6722          0.0           1.0             1.0           0.0             1.0   \n6723          0.0           1.0             1.0           0.0             1.0   \n\n      attr_4_solid  attr_4_typography  attr_5_long sleeves  \\\n0              0.0                0.0                  0.0   \n1              1.0                0.0                  0.0   \n2              1.0                0.0                  0.0   \n3              1.0                0.0                  0.0   \n4              1.0                0.0                  0.0   \n...            ...                ...                  ...   \n6719           0.0                0.0                  0.0   \n6720           0.0                0.0                  0.0   \n6721           0.0                0.0                  0.0   \n6722           0.0                0.0                  0.0   \n6723           0.0                0.0                  0.0   \n\n      attr_5_short sleeves  \n0                      1.0  \n1                      1.0  \n2                      1.0  \n3                      1.0  \n4                      1.0  \n...                    ...  \n6719                   1.0  \n6720                   1.0  \n6721                   1.0  \n6722                   1.0  \n6723                   1.0  \n\n[6724 rows x 16 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>image_path</th>\n      <th>attr_1_black</th>\n      <th>attr_1_default</th>\n      <th>attr_1_multicolor</th>\n      <th>attr_1_white</th>\n      <th>attr_2_polo</th>\n      <th>attr_2_round</th>\n      <th>attr_3_printed</th>\n      <th>attr_3_solid</th>\n      <th>attr_4_default</th>\n      <th>attr_4_solid</th>\n      <th>attr_4_typography</th>\n      <th>attr_5_long sleeves</th>\n      <th>attr_5_short sleeves</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/000...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6719</th>\n      <td>007401</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6720</th>\n      <td>007412</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6721</th>\n      <td>007417</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6722</th>\n      <td>007419</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6723</th>\n      <td>007426</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/train_images/007...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6724 rows × 16 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df2['image_path'] = df2['id'].apply(lambda x: f\"/kaggle/input/visual-taxonomy/test_images/{str(x).zfill(6)}.jpg\")\ndf2","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:55.492202Z","iopub.execute_input":"2024-11-13T09:26:55.492608Z","iopub.status.idle":"2024-11-13T09:26:55.523662Z","shell.execute_reply.started":"2024-11-13T09:26:55.492561Z","shell.execute_reply":"2024-11-13T09:26:55.522785Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"           id             Category  \\\n0      000000          Men Tshirts   \n1      000001          Men Tshirts   \n2      000002          Men Tshirts   \n3      000003          Men Tshirts   \n4      000004          Men Tshirts   \n...       ...                  ...   \n30200  030484  Women Tops & Tunics   \n30201  030485  Women Tops & Tunics   \n30202  030486  Women Tops & Tunics   \n30203  030487  Women Tops & Tunics   \n30204  030488  Women Tops & Tunics   \n\n                                              image_path  \n0      /kaggle/input/visual-taxonomy/test_images/0000...  \n1      /kaggle/input/visual-taxonomy/test_images/0000...  \n2      /kaggle/input/visual-taxonomy/test_images/0000...  \n3      /kaggle/input/visual-taxonomy/test_images/0000...  \n4      /kaggle/input/visual-taxonomy/test_images/0000...  \n...                                                  ...  \n30200  /kaggle/input/visual-taxonomy/test_images/0304...  \n30201  /kaggle/input/visual-taxonomy/test_images/0304...  \n30202  /kaggle/input/visual-taxonomy/test_images/0304...  \n30203  /kaggle/input/visual-taxonomy/test_images/0304...  \n30204  /kaggle/input/visual-taxonomy/test_images/0304...  \n\n[30205 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0000...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000001</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0000...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000002</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0000...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000003</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0000...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000004</td>\n      <td>Men Tshirts</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0000...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30200</th>\n      <td>030484</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n    </tr>\n    <tr>\n      <th>30201</th>\n      <td>030485</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n    </tr>\n    <tr>\n      <th>30202</th>\n      <td>030486</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n    </tr>\n    <tr>\n      <th>30203</th>\n      <td>030487</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n    </tr>\n    <tr>\n      <th>30204</th>\n      <td>030488</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>/kaggle/input/visual-taxonomy/test_images/0304...</td>\n    </tr>\n  </tbody>\n</table>\n<p>30205 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_df = df2.copy()","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:55.524662Z","iopub.execute_input":"2024-11-13T09:26:55.526062Z","iopub.status.idle":"2024-11-13T09:26:55.533204Z","shell.execute_reply.started":"2024-11-13T09:26:55.526029Z","shell.execute_reply":"2024-11-13T09:26:55.532266Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch.optim as optim\nimport torch.nn as nn\n\n# Load the feature extractor\nfeature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n\n# Set device (GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:26:55.534480Z","iopub.execute_input":"2024-11-13T09:26:55.535093Z","iopub.status.idle":"2024-11-13T09:27:20.840601Z","shell.execute_reply.started":"2024-11-13T09:26:55.535049Z","shell.execute_reply":"2024-11-13T09:27:20.839701Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7414092c5afd4e0f8c8e82433cda3a47"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Custom dataset class for ViT\nclass ProductDataset(torch.utils.data.Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image_path = row['image_path']\n        image = Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        labels = row.iloc[3:].values.astype(float)  # Starting from 4th column onwards (attributes)\n        return image, torch.tensor(labels, dtype=torch.float32)\n\n# Apply ViT feature extractor transformations to the dataset\ndef vit_transform(image):\n    return feature_extractor(images=image, return_tensors=\"pt\").pixel_values[0]\n\n# Prepare dataset\ndef prepare_dataset(df):\n    return ProductDataset(df, transform=vit_transform)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:49.011352Z","iopub.execute_input":"2024-11-13T09:30:49.011753Z","iopub.status.idle":"2024-11-13T09:30:49.020232Z","shell.execute_reply.started":"2024-11-13T09:30:49.011704Z","shell.execute_reply":"2024-11-13T09:30:49.019355Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Initialize the ViT model for multi-label classification\ndef create_vit_model(num_labels):\n    model = ViTForImageClassification.from_pretrained(\n        'google/vit-base-patch16-224-in21k',\n        num_labels=num_labels\n    )\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.3),\n        nn.Linear(model.config.hidden_size, num_labels)\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:49.189135Z","iopub.execute_input":"2024-11-13T09:30:49.189759Z","iopub.status.idle":"2024-11-13T09:30:49.195102Z","shell.execute_reply.started":"2024-11-13T09:30:49.189718Z","shell.execute_reply":"2024-11-13T09:30:49.194016Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def train_vit_model(model, dataloader, num_epochs=1):\n    model = model.to(device)\n    criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images).logits  # Forward pass\n            loss = criterion(outputs, labels)\n            loss.backward()  # Backpropagation\n            optimizer.step()  # Update weights\n            running_loss += loss.item()\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:49.426020Z","iopub.execute_input":"2024-11-13T09:30:49.426773Z","iopub.status.idle":"2024-11-13T09:30:49.433762Z","shell.execute_reply.started":"2024-11-13T09:30:49.426728Z","shell.execute_reply":"2024-11-13T09:30:49.432789Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Generalized function for creating and training the ViT model for any category\ndef create_and_train_vit_model_for_category(df_encoded, category_name, num_epochs=3):\n    # Calculate the number of labels based on the encoded dataframe\n    num_labels = df_encoded.shape[1] - 3  # Subtract 'id', 'Category', 'image_path'\n    \n    # Create the ViT model\n    vit_model = create_vit_model(num_labels)\n\n    # Prepare dataset and DataLoader\n    train_dataset = prepare_dataset(df_encoded)\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n    # Train the model\n    trained_model = train_vit_model(vit_model, train_loader, num_epochs)\n\n    # Save the trained model\n    model_filename = f'vit_model_{category_name}.pth'\n    torch.save(trained_model.state_dict(), model_filename)\n    print(f\"Model for {category_name} saved as {model_filename}\")\n    \n    return trained_model","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:50.136524Z","iopub.execute_input":"2024-11-13T09:30:50.137177Z","iopub.status.idle":"2024-11-13T09:30:50.144212Z","shell.execute_reply.started":"2024-11-13T09:30:50.137135Z","shell.execute_reply":"2024-11-13T09:30:50.143265Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Function to load and test the model for a given category\ndef test_vit_model(df_test, category_name, num_labels):\n    # Prepare test dataset\n    test_dataset = prepare_dataset(df_test)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n    # Load the trained model\n    model = create_vit_model(num_labels)\n    model.load_state_dict(torch.load(f'vit_model_{category_name}.pth'))\n    model = model.to(device)\n    model.eval()\n\n    # Make predictions\n    predictions = []\n    with torch.no_grad():\n        for images, ids in test_loader:\n            images = images.to(device)\n            outputs = model(images).logits\n            preds = torch.sigmoid(outputs)\n            predictions.append(preds.cpu().numpy())\n            \n    return np.concatenate(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:50.834995Z","iopub.execute_input":"2024-11-13T09:30:50.835986Z","iopub.status.idle":"2024-11-13T09:30:50.842785Z","shell.execute_reply.started":"2024-11-13T09:30:50.835940Z","shell.execute_reply":"2024-11-13T09:30:50.841781Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Decode predictions using the OneHotEncoder dynamically based on the category and number of attributes\ndef decode_predictions(predictions, encoder):\n    decoded_predictions = []\n\n    for pred in predictions:\n        decoded = []\n        val = 0\n        for i in range(len(encoder.categories_)):\n            # Get the probabilities for the current attribute (i-th group of one-hot encoded columns)\n            attr_probs = pred[val : val + len(encoder.categories_[i])]\n            val = val + len(encoder.categories_[i])\n            \n            # Ensure that we pick the category with the highest probability, even if all are below the threshold\n            max_index = np.argmax(attr_probs)  # Find the index of the highest probability\n            \n            decoded.append(encoder.categories_[i][max_index])  # Use the encoder to map back the category\n\n        decoded_predictions.append(decoded)\n\n    return np.array(decoded_predictions)\n\ndef prepare_submission(df_test, decoded_attributes, category_name, num_attributes):\n    # Prepare the submission data\n    submission_data = {\n        'id': df_test['id'].values  # Include the 'id' column\n    }\n\n    # Get the actual number of decoded attributes from the shape of decoded_attributes\n    actual_num_attributes = decoded_attributes.shape[1]\n\n    # Dynamically add attribute columns to the dictionary based on the actual number of decoded attributes\n    for i in range(1, actual_num_attributes + 1):\n        submission_data[f'attr_{i}'] = decoded_attributes[:, i - 1]  # Adjust for zero-indexing in arrays\n\n    # Convert the dictionary to a DataFrame\n    submission_df = pd.DataFrame(submission_data)\n    \n    # Save the submission DataFrame to a CSV file\n    submission_filename = f\"{category_name}_predictions.csv\"\n    submission_df.to_csv(submission_filename, index=False)\n    print(f\"Submission file saved: {submission_filename}\")\n    \n\n# Generalized function to handle decoding and submission for any category\ndef decode_and_save_submission(predictions, df_test, encoder, category_name, num_attributes):\n    # Convert the predictions array\n    pred_array = predictions\n    \n    # Decode the predictions using the stored OneHotEncoder\n    decoded_attributes = decode_predictions(pred_array, encoder)\n    \n    # Prepare the submission DataFrame\n    submission_df = prepare_submission(df_test, decoded_attributes, num_attributes)\n    \n    # Save the submission DataFrame to CSV\n    submission_file = f'{category_name}_predictions.csv'\n    submission_df.to_csv(submission_file, index=False)\n    \n    print(f\"Submission file for {category_name} saved as {submission_file}\")\n    \n    return submission_df","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:51.311101Z","iopub.execute_input":"2024-11-13T09:30:51.311960Z","iopub.status.idle":"2024-11-13T09:30:51.323171Z","shell.execute_reply.started":"2024-11-13T09:30:51.311917Z","shell.execute_reply":"2024-11-13T09:30:51.322332Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Function to save the trained model for a specific category\ndef save_model(trained_model, category_name):\n    model_filename = f'vit_model_{category_name}.pth'\n    torch.save(trained_model.state_dict(), model_filename)\n    print(f\"Model for {category_name} saved as {model_filename}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:52.472610Z","iopub.execute_input":"2024-11-13T09:30:52.473020Z","iopub.status.idle":"2024-11-13T09:30:52.479262Z","shell.execute_reply.started":"2024-11-13T09:30:52.472981Z","shell.execute_reply":"2024-11-13T09:30:52.478282Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"categories = ['Sarees', 'Kurtis', 'Women Tshirts', 'Women Tops & Tunics', 'Men Tshirts']","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:52.828768Z","iopub.execute_input":"2024-11-13T09:30:52.829659Z","iopub.status.idle":"2024-11-13T09:30:52.834035Z","shell.execute_reply.started":"2024-11-13T09:30:52.829615Z","shell.execute_reply":"2024-11-13T09:30:52.833093Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def pipeline(categories, category_dfs_encoded, test_df , num_epoch = 3):\n    # Loop over each category provided in the input\n    for category in categories:\n        print(f\"\\nProcessing category: {category}\")\n        \n        # 1. Prepare the dataset and dataloader for the category\n        df_encoded = category_dfs_encoded[category]  # Get the encoded dataframe for the category\n        \n        # 2. Create and train the model for this category\n        num_labels = df_encoded.shape[1] - 3  # Subtract 'id', 'Category', 'image_path'\n        trained_model = create_and_train_vit_model_for_category(df_encoded ,category,num_epoch)\n        \n        # 3. Save the trained model\n        save_model(trained_model, category)\n        \n        # 4. Prepare the test data for this category\n        df_test_category = test_df[test_df['Category'] == category].copy()\n        df_test_category['image_path'] = df_test_category['id'].apply(lambda x: f\"/kaggle/input/visual-taxonomy/test_images/{x}.jpg\")\n        test_dataset = prepare_dataset(df_test_category)  # Prepare the test dataset\n        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n        \n        # 5. Test the model on the test data\n        predictions = test_vit_model(df_test_category, category, num_labels)  # Get predictions\n        print(pd.DataFrame(predictions))\n        \n        # 6. Decode the predictions using the stored OneHotEncoder\n        pred_array = np.concatenate(predictions, axis=0)  # Concatenate along rows\n        pred_array = pred_array.reshape(-1, num_labels)  # Reshape to (samples, num_labels)\n        \n        decoded_predictions = decode_predictions(pred_array, encoders[category])\n        print(pd.DataFrame(decoded_predictions))\n        \n        \n        # 7. Prepare and save the submission for this category\n        prepare_submission(df_test_category, decoded_predictions, category, num_labels)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:55.131259Z","iopub.execute_input":"2024-11-13T09:30:55.132115Z","iopub.status.idle":"2024-11-13T09:30:55.140758Z","shell.execute_reply.started":"2024-11-13T09:30:55.132070Z","shell.execute_reply":"2024-11-13T09:30:55.139813Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"pipeline(categories, category_dfs_encoded, test_df, num_epoch = 10)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:27:50.900365Z","iopub.execute_input":"2024-11-13T09:27:50.900654Z","iopub.status.idle":"2024-11-13T09:27:50.915371Z","shell.execute_reply.started":"2024-11-13T09:27:50.900622Z","shell.execute_reply":"2024-11-13T09:27:50.914596Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# alldf = []\n# for i in categories:\n#     df = pd.read_csv(f'/kaggle/input/output/{i}_predictions (1).csv')\n#     alldf.append(df)\n    \n    \n# alldf = []\n# for i in categories:\n#     if i == 'Women Tops & Tunics':\n#         i = 'Women Tops and Tunics'\n#     df = pd.read_csv(f'/kaggle/input/ouputt/{i}_predictions (1).csv')\n#     alldf.append(df)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.629418Z","iopub.execute_input":"2024-11-12T17:49:23.629736Z","iopub.status.idle":"2024-11-12T17:49:23.634174Z","shell.execute_reply.started":"2024-11-12T17:49:23.629703Z","shell.execute_reply":"2024-11-12T17:49:23.633226Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nimport os\nimport torch.optim as optim\nimport torch.nn as nn\n\n# Load the ViT feature extractor\nfeature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n\n# Set device (GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Custom dataset class for ViT\nclass ProductDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        image_path = row['image_path']\n        image = Image.open(image_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        labels = row.iloc[3:].values.astype(float)  # Starting from 4th column onwards (attributes)\n        return image, torch.tensor(labels, dtype=torch.float32)\n\n# Apply ViT feature extractor transformations to the dataset\ndef vit_transform(image):\n    return feature_extractor(images=image, return_tensors=\"pt\").pixel_values[0]\n\n# Prepare dataset\ndef prepare_dataset(df):\n    return ProductDataset(df, transform=vit_transform)\n\n# Initialize the ViT model for multi-label classification\ndef create_vit_model(num_labels):\n    model = ViTForImageClassification.from_pretrained(\n        'google/vit-base-patch16-224-in21k',\n        num_labels=num_labels\n    )\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.3),\n        nn.Linear(model.config.hidden_size, num_labels)\n    )\n    return model\n\n# Training function with early stopping\ndef train_vit_model_with_early_stopping(model, train_loader, val_loader, num_epochs=10, patience=3):\n    model = model.to(device)\n    criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\n    best_val_loss = float('inf')\n    patience_counter = 0\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images).logits\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        train_loss = running_loss / len(train_loader)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images).logits\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n\n        # Early stopping check\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            # Save the best model\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(\"Validation loss improved, saving model.\")\n        else:\n            patience_counter += 1\n            print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n\n        # Check if we should stop early\n        if patience_counter >= patience:\n            print(\"Early stopping triggered. Training stopped.\")\n            break\n\n    # Load the best model\n    model.load_state_dict(torch.load('best_model.pth'))\n    return model\n\n# Generalized function for creating, training, and early-stopping the ViT model\ndef create_and_train_vit_model_for_category(df_encoded, val_df, category_name, num_epochs=10, patience=3):\n    num_labels = df_encoded.shape[1] - 3  # Subtract 'id', 'Category', 'image_path'\n    vit_model = create_vit_model(num_labels)\n\n    # Prepare datasets and DataLoaders\n    train_dataset = prepare_dataset(df_encoded)\n    val_dataset = prepare_dataset(val_df)\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n    # Train model with early stopping\n    trained_model = train_vit_model_with_early_stopping(vit_model, train_loader, val_loader, num_epochs, patience)\n\n    # Save the trained model\n    model_filename = f'vit_model_{category_name}.pth'\n    torch.save(trained_model.state_dict(), model_filename)\n    print(f\"Model for {category_name} saved as {model_filename}\")\n\n    return trained_model\n\n# Testing function for ViT model\ndef test_vit_model(df_test, category_name, num_labels):\n    test_dataset = prepare_dataset(df_test)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n    # Load the trained model\n    model = create_vit_model(num_labels)\n    model.load_state_dict(torch.load(f'vit_model_{category_name}.pth'))\n    model = model.to(device)\n    model.eval()\n\n    predictions = []\n    with torch.no_grad():\n        for images, _ in test_loader:\n            images = images.to(device)\n            outputs = model(images).logits\n            preds = torch.sigmoid(outputs)\n            predictions.append(preds.cpu().numpy())\n    \n    return np.concatenate(predictions, axis=0)\n\n# Helper functions for decoding predictions and preparing submissions would go here\n# Similar to your original setup, we assume a function called decode_predictions exists\n\n# Pipeline function for training, testing, and submission preparation\ndef pipeline(categories, category_dfs_encoded, category_dfs_val, test_df, num_epoch=10, patience=3):\n    for category in categories:\n        print(f\"\\nProcessing category: {category}\")\n        \n        # Load data for the category\n        df_encoded = category_dfs_encoded[category]\n        val_df = category_dfs_val[category]\n        num_labels = df_encoded.shape[1] - 3  # Adjust for other columns\n\n        # Train with early stopping\n        trained_model = create_and_train_vit_model_for_category(df_encoded, val_df, category, num_epoch, patience)\n\n        # Prepare and save test predictions\n        df_test_category = test_df[test_df['Category'] == category].copy()\n        df_test_category['image_path'] = df_test_category['id'].apply(lambda x: f\"/path/to/test_images/{x}.jpg\")\n        predictions = test_vit_model(df_test_category, category, num_labels)\n        \n        # Decode and save predictions for submission\n        decoded_predictions = decode_predictions(predictions, encoders[category])\n        prepare_submission(df_test_category, decoded_predictions, category, num_labels)\n\n# Run the pipeline with your categories and data\n# Replace category_dfs_encoded, category_dfs_val, test_df, and encoders with actual data\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:30:57.605083Z","iopub.execute_input":"2024-11-13T09:30:57.605468Z","iopub.status.idle":"2024-11-13T09:30:57.855606Z","shell.execute_reply.started":"2024-11-13T09:30:57.605431Z","shell.execute_reply":"2024-11-13T09:30:57.854811Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"\ncategories = ['Sarees', 'Kurtis', 'Women Tshirts', 'Women Tops & Tunics', 'Men Tshirts']\npipeline(categories, category_dfs_encoded, category_dfs_encoded, test_df, num_epoch=20, patience=4)","metadata":{"execution":{"iopub.status.busy":"2024-11-13T09:31:38.042277Z","iopub.execute_input":"2024-11-13T09:31:38.043129Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"\nProcessing category: Sarees\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4688e03c37a74a8aba2a8bbdd3690357"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fa7d543c3ea43c4a7cbffd542743b4c"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20], Train Loss: 0.3132, Val Loss: 0.2487\nValidation loss improved, saving model.\nEpoch [2/20], Train Loss: 0.2397, Val Loss: 0.2306\nValidation loss improved, saving model.\nEpoch [3/20], Train Loss: 0.2297, Val Loss: 0.2240\nValidation loss improved, saving model.\nEpoch [4/20], Train Loss: 0.2251, Val Loss: 0.2208\nValidation loss improved, saving model.\n","output_type":"stream"}]},{"cell_type":"code","source":"alldf = []\nfor i in categories:\n    df = pd.read_csv(f'/kaggle/working/{i}_predictions.csv')\n    alldf.append(df)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.635270Z","iopub.execute_input":"2024-11-12T17:49:23.635556Z","iopub.status.idle":"2024-11-12T17:49:23.701859Z","shell.execute_reply.started":"2024-11-12T17:49:23.635525Z","shell.execute_reply":"2024-11-12T17:49:23.701026Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"len(alldf)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.706924Z","iopub.execute_input":"2024-11-12T17:49:23.707247Z","iopub.status.idle":"2024-11-12T17:49:23.713165Z","shell.execute_reply.started":"2024-11-12T17:49:23.707213Z","shell.execute_reply":"2024-11-12T17:49:23.712266Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"df_final = pd.concat(alldf, axis = 0)\ndf_final = df_final.sort_values(by = 'id')\ndf_final.reset_index(drop= True, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.714292Z","iopub.execute_input":"2024-11-12T17:49:23.714634Z","iopub.status.idle":"2024-11-12T17:49:23.733722Z","shell.execute_reply.started":"2024-11-12T17:49:23.714601Z","shell.execute_reply":"2024-11-12T17:49:23.733018Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"df_final = pd.concat([df_final, pd.read_csv('/kaggle/input/visual-taxonomy/test.csv')['Category']], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.734943Z","iopub.execute_input":"2024-11-12T17:49:23.735237Z","iopub.status.idle":"2024-11-12T17:49:23.758325Z","shell.execute_reply.started":"2024-11-12T17:49:23.735204Z","shell.execute_reply":"2024-11-12T17:49:23.757428Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df_final['len'] = df_final['Category'].map(category_attributes)\ndf_final = df_final[sample.columns]\ndf_final.fillna('extra', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.759533Z","iopub.execute_input":"2024-11-12T17:49:23.759914Z","iopub.status.idle":"2024-11-12T17:49:23.812246Z","shell.execute_reply.started":"2024-11-12T17:49:23.759869Z","shell.execute_reply":"2024-11-12T17:49:23.811473Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"df_final.to_csv('meesho_submission29_autoep_3na_knn25.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:23.813331Z","iopub.execute_input":"2024-11-12T17:49:23.813627Z","iopub.status.idle":"2024-11-12T17:49:24.042416Z","shell.execute_reply.started":"2024-11-12T17:49:23.813594Z","shell.execute_reply":"2024-11-12T17:49:24.041292Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df_final","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:24.043842Z","iopub.execute_input":"2024-11-12T17:49:24.044133Z","iopub.status.idle":"2024-11-12T17:49:24.061673Z","shell.execute_reply.started":"2024-11-12T17:49:24.044097Z","shell.execute_reply":"2024-11-12T17:49:24.060811Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"          id             Category  len      attr_1   attr_2   attr_3  \\\n0          0          Men Tshirts    5  multicolor    round  printed   \n1          1          Men Tshirts    5       white    round  printed   \n2          2          Men Tshirts    5       white    round  printed   \n3          3          Men Tshirts    5     default     polo    solid   \n4          4          Men Tshirts    5  multicolor    round  printed   \n...      ...                  ...  ...         ...      ...      ...   \n30200  30484  Women Tops & Tunics   10       green     boxy     crop   \n30201  30485  Women Tops & Tunics   10        blue  regular  regular   \n30202  30486  Women Tops & Tunics   10     default  regular  regular   \n30203  30487  Women Tops & Tunics   10  multicolor  regular  regular   \n30204  30488  Women Tops & Tunics   10        pink   fitted     crop   \n\n            attr_4         attr_5   attr_6      attr_7         attr_8  \\\n0          default  short sleeves    extra       extra          extra   \n1          default  short sleeves    extra       extra          extra   \n2          default  short sleeves    extra       extra          extra   \n3            solid  short sleeves    extra       extra          extra   \n4          default  short sleeves    extra       extra          extra   \n...            ...            ...      ...         ...            ...   \n30200   round neck         casual  printed  typography  short sleeves   \n30201   round neck         casual    solid       solid  short sleeves   \n30202  square neck         casual    solid       solid  short sleeves   \n30203   round neck         casual  printed     default   long sleeves   \n30204      default         casual    solid       solid     sleeveless   \n\n                attr_9  attr_10  \n0                extra    extra  \n1                extra    extra  \n2                extra    extra  \n3                extra    extra  \n4                extra    extra  \n...                ...      ...  \n30200  regular sleeves  ruffles  \n30201     puff sleeves  knitted  \n30202     puff sleeves  knitted  \n30203  regular sleeves  ruffles  \n30204          default  knitted  \n\n[30205 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>white</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>white</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30200</th>\n      <td>30484</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>green</td>\n      <td>boxy</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>typography</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n    </tr>\n    <tr>\n      <th>30201</th>\n      <td>30485</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>blue</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>puff sleeves</td>\n      <td>knitted</td>\n    </tr>\n    <tr>\n      <th>30202</th>\n      <td>30486</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>default</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>square neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>puff sleeves</td>\n      <td>knitted</td>\n    </tr>\n    <tr>\n      <th>30203</th>\n      <td>30487</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>multicolor</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>long sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n    </tr>\n    <tr>\n      <th>30204</th>\n      <td>30488</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>pink</td>\n      <td>fitted</td>\n      <td>crop</td>\n      <td>default</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>sleeveless</td>\n      <td>default</td>\n      <td>knitted</td>\n    </tr>\n  </tbody>\n</table>\n<p>30205 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.read_csv('/kaggle/working/meesho_submission26_10ep_4na_knn17.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-12T17:49:24.062805Z","iopub.execute_input":"2024-11-12T17:49:24.063121Z","iopub.status.idle":"2024-11-12T17:49:24.144974Z","shell.execute_reply.started":"2024-11-12T17:49:24.063090Z","shell.execute_reply":"2024-11-12T17:49:24.144047Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"          id             Category  len      attr_1   attr_2   attr_3  \\\n0          0          Men Tshirts    5  multicolor    round  printed   \n1          1          Men Tshirts    5       white    round  printed   \n2          2          Men Tshirts    5       white    round  printed   \n3          3          Men Tshirts    5     default     polo    solid   \n4          4          Men Tshirts    5  multicolor    round  printed   \n...      ...                  ...  ...         ...      ...      ...   \n30200  30484  Women Tops & Tunics   10       green     boxy     crop   \n30201  30485  Women Tops & Tunics   10        blue  regular  regular   \n30202  30486  Women Tops & Tunics   10     default  regular  regular   \n30203  30487  Women Tops & Tunics   10  multicolor  regular  regular   \n30204  30488  Women Tops & Tunics   10        pink   fitted     crop   \n\n            attr_4         attr_5   attr_6      attr_7         attr_8  \\\n0          default  short sleeves    extra       extra          extra   \n1          default  short sleeves    extra       extra          extra   \n2          default  short sleeves    extra       extra          extra   \n3            solid  short sleeves    extra       extra          extra   \n4          default  short sleeves    extra       extra          extra   \n...            ...            ...      ...         ...            ...   \n30200   round neck         casual  printed  typography  short sleeves   \n30201   round neck         casual    solid       solid  short sleeves   \n30202  square neck         casual    solid       solid  short sleeves   \n30203   round neck         casual  printed     default   long sleeves   \n30204      default         casual    solid       solid     sleeveless   \n\n                attr_9  attr_10  \n0                extra    extra  \n1                extra    extra  \n2                extra    extra  \n3                extra    extra  \n4                extra    extra  \n...                ...      ...  \n30200  regular sleeves  ruffles  \n30201     puff sleeves  knitted  \n30202     puff sleeves  knitted  \n30203  regular sleeves  ruffles  \n30204          default  knitted  \n\n[30205 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Category</th>\n      <th>len</th>\n      <th>attr_1</th>\n      <th>attr_2</th>\n      <th>attr_3</th>\n      <th>attr_4</th>\n      <th>attr_5</th>\n      <th>attr_6</th>\n      <th>attr_7</th>\n      <th>attr_8</th>\n      <th>attr_9</th>\n      <th>attr_10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>white</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>white</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>default</td>\n      <td>polo</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Men Tshirts</td>\n      <td>5</td>\n      <td>multicolor</td>\n      <td>round</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>short sleeves</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n      <td>extra</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30200</th>\n      <td>30484</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>green</td>\n      <td>boxy</td>\n      <td>crop</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>typography</td>\n      <td>short sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n    </tr>\n    <tr>\n      <th>30201</th>\n      <td>30485</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>blue</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>puff sleeves</td>\n      <td>knitted</td>\n    </tr>\n    <tr>\n      <th>30202</th>\n      <td>30486</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>default</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>square neck</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>short sleeves</td>\n      <td>puff sleeves</td>\n      <td>knitted</td>\n    </tr>\n    <tr>\n      <th>30203</th>\n      <td>30487</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>multicolor</td>\n      <td>regular</td>\n      <td>regular</td>\n      <td>round neck</td>\n      <td>casual</td>\n      <td>printed</td>\n      <td>default</td>\n      <td>long sleeves</td>\n      <td>regular sleeves</td>\n      <td>ruffles</td>\n    </tr>\n    <tr>\n      <th>30204</th>\n      <td>30488</td>\n      <td>Women Tops &amp; Tunics</td>\n      <td>10</td>\n      <td>pink</td>\n      <td>fitted</td>\n      <td>crop</td>\n      <td>default</td>\n      <td>casual</td>\n      <td>solid</td>\n      <td>solid</td>\n      <td>sleeveless</td>\n      <td>default</td>\n      <td>knitted</td>\n    </tr>\n  </tbody>\n</table>\n<p>30205 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import torch\n# from transformers import ViTForImageClassification, ViTFeatureExtractor\n# from torch.utils.data import DataLoader\n# from PIL import Image\n# import pandas as pd\n# import numpy as np\n# import os\n# import torch.optim as optim\n# import torch.nn as nn\n\n# # Load the feature extractor\n# feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n\n# # Set device (GPU or CPU)\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# # Custom dataset class for ViT\n# class ProductDataset(torch.utils.data.Dataset):\n#     def __init__(self, dataframe, transform=None):\n#         self.dataframe = dataframe\n#         self.transform = transform\n\n#     def __len__(self):\n#         return len(self.dataframe)\n\n#     def __getitem__(self, idx):\n#         row = self.dataframe.iloc[idx]\n#         image_path = row['image_path']\n#         image = Image.open(image_path).convert('RGB')\n#         if self.transform:\n#             image = self.transform(image)\n#         labels = row.iloc[3:].values.astype(float)  # Starting from 4th column onwards (attributes)\n#         return image, torch.tensor(labels, dtype=torch.float32)\n\n# # Apply ViT feature extractor transformations to the dataset\n# def vit_transform(image):\n#     return feature_extractor(images=image, return_tensors=\"pt\").pixel_values[0]\n\n# # Prepare dataset\n# def prepare_dataset(df):\n#     return ProductDataset(df, transform=vit_transform)\n\n# # Initialize the ViT model for multi-label classification\n# def create_vit_model(num_labels):\n#     model = ViTForImageClassification.from_pretrained(\n#         'google/vit-base-patch16-224-in21k',\n#         num_labels=num_labels\n#     )\n#     model.classifier = nn.Sequential(\n#         nn.Dropout(p=0.3),\n#         nn.Linear(model.config.hidden_size, num_labels)\n#     )\n#     return model\n\n# def train_vit_model(model, dataloader, num_epochs=1):\n#     model = model.to(device)\n#     criterion = nn.BCEWithLogitsLoss()  # Suitable for multi-label classification\n#     optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n\n#     model.train()\n#     for epoch in range(num_epochs):\n#         running_loss = 0.0\n#         for images, labels in dataloader:\n#             images, labels = images.to(device), labels.to(device)\n#             optimizer.zero_grad()\n#             outputs = model(images).logits  # Forward pass\n#             loss = criterion(outputs, labels)\n#             loss.backward()  # Backpropagation\n#             optimizer.step()  # Update weights\n#             running_loss += loss.item()\n#         print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n    \n#     return model\n\n# # Generalized function for creating and training the ViT model for any category\n# def create_and_train_vit_model_for_category(df_encoded, category_name, num_epochs=3):\n#     # Calculate the number of labels based on the encoded dataframe\n#     num_labels = df_encoded.shape[1] - 3  # Subtract 'id', 'Category', 'image_path'\n    \n#     # Create the ViT model\n#     vit_model = create_vit_model(num_labels)\n\n#     # Prepare dataset and DataLoader\n#     train_dataset = prepare_dataset(df_encoded)\n#     train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n#     # Train the model\n#     trained_model = train_vit_model(vit_model, train_loader, num_epochs)\n\n#     # Save the trained model\n#     model_filename = f'vit_model_{category_name}.pth'\n#     torch.save(trained_model.state_dict(), model_filename)\n#     print(f\"Model for {category_name} saved as {model_filename}\")\n    \n#     return trained_model\n\n# # Function to load and test the model for a given category\n# def test_vit_model(df_test, category_name, num_labels):\n#     # Prepare test dataset\n#     test_dataset = prepare_dataset(df_test)\n#     test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n#     # Load the trained model\n#     model = create_vit_model(num_labels)\n#     model.load_state_dict(torch.load(f'vit_model_{category_name}.pth'))\n#     model = model.to(device)\n#     model.eval()\n\n#     # Make predictions\n#     predictions = []\n#     with torch.no_grad():\n#         for images, ids in test_loader:\n#             images = images.to(device)\n#             outputs = model(images).logits\n#             preds = torch.sigmoid(outputs)\n#             predictions.append(preds.cpu().numpy())\n            \n#     return np.concatenate(predictions, axis=0)\n\n# # Decode predictions using the OneHotEncoder dynamically based on the category and number of attributes\n# def decode_predictions(predictions, encoder):\n#     decoded_predictions = []\n\n#     for pred in predictions:\n#         decoded = []\n#         val = 0\n#         for i in range(len(encoder.categories_)):\n#             # Get the probabilities for the current attribute (i-th group of one-hot encoded columns)\n#             attr_probs = pred[val : val + len(encoder.categories_[i])]\n#             val = val + len(encoder.categories_[i])\n            \n#             # Ensure that we pick the category with the highest probability, even if all are below the threshold\n#             max_index = np.argmax(attr_probs)  # Find the index of the highest probability\n            \n#             decoded.append(encoder.categories_[i][max_index])  # Use the encoder to map back the category\n\n#         decoded_predictions.append(decoded)\n\n#     return np.array(decoded_predictions)\n\n# def prepare_submission(df_test, decoded_attributes, category_name, num_attributes):\n#     # Prepare the submission data\n#     submission_data = {\n#         'id': df_test['id'].values  # Include the 'id' column\n#     }\n\n#     # Get the actual number of decoded attributes from the shape of decoded_attributes\n#     actual_num_attributes = decoded_attributes.shape[1]\n\n#     # Dynamically add attribute columns to the dictionary based on the actual number of decoded attributes\n#     for i in range(1, actual_num_attributes + 1):\n#         submission_data[f'attr_{i}'] = decoded_attributes[:, i - 1]  # Adjust for zero-indexing in arrays\n\n#     # Convert the dictionary to a DataFrame\n#     submission_df = pd.DataFrame(submission_data)\n    \n#     # Save the submission DataFrame to a CSV file\n#     submission_filename = f\"{category_name}_predictions.csv\"\n#     submission_df.to_csv(submission_filename, index=False)\n#     print(f\"Submission file saved: {submission_filename}\")\n    \n\n# # Generalized function to handle decoding and submission for any category\n# def decode_and_save_submission(predictions, df_test, encoder, category_name, num_attributes):\n#     # Convert the predictions array\n#     pred_array = predictions\n    \n#     # Decode the predictions using the stored OneHotEncoder\n#     decoded_attributes = decode_predictions(pred_array, encoder)\n    \n#     # Prepare the submission DataFrame\n#     submission_df = prepare_submission(df_test, decoded_attributes, num_attributes)\n    \n#     # Save the submission DataFrame to CSV\n#     submission_file = f'{category_name}_predictions.csv'\n#     submission_df.to_csv(submission_file, index=False)\n    \n#     print(f\"Submission file for {category_name} saved as {submission_file}\")\n    \n#     return submission_df\n\n# # Function to save the trained model for a specific category\n# def save_model(trained_model, category_name):\n#     model_filename = f'vit_model_{category_name}.pth'\n#     torch.save(trained_model.state_dict(), model_filename)\n#     print(f\"Model for {category_name} saved as {model_filename}\")\n    \n# categories = ['Sarees', 'Kurtis', 'Women Tshirts', 'Women Tops & Tunics', 'Men Tshirts']\n\n# def pipeline(categories, category_dfs_encoded, test_df , num_epoch = 3):\n#     # Loop over each category provided in the input\n#     for category in categories:\n#         print(f\"\\nProcessing category: {category}\")\n        \n#         # 1. Prepare the dataset and dataloader for the category\n#         df_encoded = category_dfs_encoded[category]  # Get the encoded dataframe for the category\n        \n#         # 2. Create and train the model for this category\n#         num_labels = df_encoded.shape[1] - 3  # Subtract 'id', 'Category', 'image_path'\n#         trained_model = create_and_train_vit_model_for_category(df_encoded ,category,num_epoch)\n        \n#         # 3. Save the trained model\n#         save_model(trained_model, category)\n        \n#         # 4. Prepare the test data for this category\n#         df_test_category = test_df[test_df['Category'] == category].copy()\n#         df_test_category['image_path'] = df_test_category['id'].apply(lambda x: f\"/kaggle/input/visual-taxonomy/test_images/{x}.jpg\")\n#         test_dataset = prepare_dataset(df_test_category)  # Prepare the test dataset\n#         test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n        \n#         # 5. Test the model on the test data\n#         predictions = test_vit_model(df_test_category, category, num_labels)  # Get predictions\n#         print(pd.DataFrame(predictions))\n        \n#         # 6. Decode the predictions using the stored OneHotEncoder\n#         pred_array = np.concatenate(predictions, axis=0)  # Concatenate along rows\n#         pred_array = pred_array.reshape(-1, num_labels)  # Reshape to (samples, num_labels)\n        \n#         decoded_predictions = decode_predictions(pred_array, encoders[category])\n#         print(pd.DataFrame(decoded_predictions))\n        \n        \n#         # 7. Prepare and save the submission for this category\n#         prepare_submission(df_test_category, decoded_predictions, category, num_labels)","metadata":{},"execution_count":null,"outputs":[]}]}